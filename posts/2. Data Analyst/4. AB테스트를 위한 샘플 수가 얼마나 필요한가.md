# 샘플 수가 얼마나 필요한가?

Post A/B 테스트의 경우, 샘플 수는 고정이다. 이 때는 적절한 유의수준을 설정해놓은 뒤, 검정을 실시하면 된다. 그 후, 유의한지, 유의하지 않은 지를 판단하면 된다. 
만약, A/B 테스트의 설계의 단계에서, 샘플 수가 얼마나 필요한지는 어떻게 설정하면 좋을까.

여기에서 고려해야 할 사항은 0. 파라미터를 어떻게 설정할 것인가. 1. 어떤 종류의 변수인가. 2. 변수의 분포가 어떠한가 로 나눌 수 있겠다.

간단한 예시로 연속형 변수의 샘플 수를 구하는 공식을 살펴보자. 

n = 2(Zα/2 + Zβ)² * (σ²) / MDE²

여기서 Zα/2는 유의수준, Zβ는 검정력, σ1은 표준편차, MDE는 효과 크기를 의미한다. 이러한 공식을 통해, 우리가 구해야 하는 샘플 수를 추정할 수 있다.

즉, 어떤 종류의 변수인가에 따라, 샘플 수를 구하는 공식을 결정하고,
유의수준, 검정력, MDE(최소 감지 효과)를 결정하면, 우리의 검정에 필요한 샘플 수를 구할 수가 있다.

> 선생님, 2. 변수의 분포가 어떠한가? 를 빼먹으셨는데요.

그러하다. 위의 샘플 수의 공식은 정규분포를 가정할 때에만 적용된다. 위의 공식을 자세히 살펴보면, 분산과 샘플 수는 비례하여 증가한다. 그러나, 데이터가 정규분포가 아니라, 멱분포를 따를 경우, 표준편차가 매우 커지기 때문에, 공식에 대입하면, 수십만에서 수천만명이라는 비현실적인 샘플 수를 구해야 할 수도 있다. 

> 그럼 어떻게 해야 하나요?
실무에서는 보통 다음 2가지 방법 중 하나를 선택하여 샘플 수를 산정할 수 있겠다.

1. 방법 A : 로그 변환

```python

```

2. 방법 B : 부트스트랩 시뮬레이션
- 부트스트랩에 대한 자세한 내용은 다른 글을 참조해주시길 바랍니다.
- 부트스트랩을 간단히 설명하자면, 컴퓨터의 계산력을 활용하여, 시뮬레이션을 돌리는 것이다. 

```python
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

# 1. 가상의 데이터 생성 (멱분포/Pareto 형태 가정)
np.random.seed(42)
# shape=1.5 (매우 꼬리가 긴 분포), scale=300초
data = stats.pareto.rvs(b=1.5, scale=300, size=10000) 

# 목표 설정
MDE = 60           # 60초 차이를 감지하고 싶음
ALPHA = 0.05       # 유의수준 5%
TARGET_POWER = 0.8 # 목표 검정력 80%
SIMULATIONS = 1000 # 각 샘플 수마다 1000번 실험

def check_power(n, data, mde, alpha, simulations):
    success_count = 0
    
    for _ in range(simulations):
        # A그룹: 원본 데이터에서 n명 복원 추출
        control = np.random.choice(data, n, replace=True)
        
        # B그룹: 원본 데이터에서 n명 추출 후 MDE(60초) 더함
        # (모든 유저가 균등하게 60초 늘어난다고 가정할 경우)
        variant = np.random.choice(data, n, replace=True) + mde
        
        # t-test 수행 (Welch's t-test 권장: 등분산 가정 X)
        t_stat, p_val = stats.ttest_ind(control, variant, equal_var=False)
        
        # 유의수준보다 낮으면 성공
        if p_val < alpha:
            success_count += 1
            
    return success_count / simulations

# 샘플 수를 늘려가며 검정력 확인
sample_sizes = [500, 1000, 2000, 3000, 5000, 10000] # 테스트할 샘플 수 후보

print(f"데이터 평균: {np.mean(data):.2f}, 데이터 표준편차: {np.std(data):.2f}")
print("-" * 50)

for n in sample_sizes:
    current_power = check_power(n, data, MDE, ALPHA, SIMULATIONS)
    print(f"샘플 수 {n}명일 때 예상 검정력: {current_power * 100:.1f}%")
    
    if current_power >= TARGET_POWER:
        print(f"--> [결과] 목표 검정력 80% 달성을 위해 그룹당 약 {n}명이 필요합니다.")
        break
```

```
데이터 평균: 822.25, 데이터 표준편차: 1792.74
--------------------------------------------------
샘플 수 500명일 때 예상 검정력: 9.7%
샘플 수 1000명일 때 예상 검정력: 14.7%
샘플 수 2000명일 때 예상 검정력: 22.4%
샘플 수 3000명일 때 예상 검정력: 27.1%
샘플 수 5000명일 때 예상 검정력: 40.8%
샘플 수 10000명일 때 예상 검정력: 65.1%
```

3. 방법 3 :

```python
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

# 1. 멱분포(Pareto) 형태의 가상 데이터 생성
np.random.seed(42)
# shape=1.5 (매우 꼬리가 긴 불평등 분포), 최소값(scale)=300초
data = stats.pareto.rvs(b=1.5, scale=300, size=10000)

# 2. 목표 설정
MDE = 60           # 60초 증가 효과
ALPHA = 0.05       # 유의수준 5%
TARGET_POWER = 0.8 # 목표 검정력 80%
SIMULATIONS = 1000 # 반복 횟수

# 3. 로그 변환 검정력 시뮬레이션 함수
def check_power_log(n, data, mde, alpha, simulations):
    success_count = 0
    
    for _ in range(simulations):
        # A그룹: n명 추출
        control = np.random.choice(data, n, replace=True)
        
        # B그룹: n명 추출 + MDE(60초) 효과 주입
        variant = np.random.choice(data, n, replace=True) + mde
        
        # --- [핵심] 로그 변환 수행 ---
        # 데이터가 0보다 크므로 바로 log 적용 (0이 포함된다면 np.log1p 사용)
        log_control = np.log(control)
        log_variant = np.log(variant)
        
        # 변환된 데이터로 t-test 수행
        t_stat, p_val = stats.ttest_ind(log_control, log_variant, equal_var=False)
        
        if p_val < alpha:
            success_count += 1
            
    return success_count / simulations

# 4. 결과 확인
sample_sizes = [100, 200, 300, 500, 1000]

print(f"{'샘플 수':<10} | {'검정력 (로그 변환 후)':<20}")
print("-" * 35)

for n in sample_sizes:
    power = check_power_log(n, data, MDE, ALPHA, SIMULATIONS)
    print(f"{n:<10} | {power * 100:.1f}%")
```

```
샘플 수       | 검정력 (로그 변환 후)       
-----------------------------------
100        | 27.0%
200        | 43.3%
300        | 62.0%
500        | 79.9%
1000       | 98.2%
```

이렇게 나왔는데, 프로토타입이나 베타버전에서 10000명을 모집하는 것은, 시간적으로나 리소스적으로나 불가능할 것이다. 이럴 경우, 로그 변환을 사용하여, 


세줄 요약
1. 
2. 샘플 수 구할 때, 분포가 어떻든 동일한 공식 써도 되나요 -> 안됨. 그대로 쓰면, 멱분포의 경우, 표준편차가 너무 켜저서 샘플 수가 과다하게 계산됨.
3. 
