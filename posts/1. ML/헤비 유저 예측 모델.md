# 초기 플레이 데이터만으로 장기적 헤비 유저를 예측하는 모델을 만들어보자

## 1. 선정 게임 : tetrapiece. (다른 게임에 대해서도 헤비 유저를 예측하고 싶다면, 그 게임만의 모델을 새롭게 설계해서 학습시켜야 함.)

## 2. 갖고 있는 데이터 
- tetrapiece의 각 OS별 버전별 데이터. iOS 0.25 ~ 0.29, Android 0.25 ~ 0.29

## 3. 결과변수 : 헤비 유저인지 아닌지, 0과 1로 판단.
### 3-1.라벨링 : 학습 데이터를  위한, 헤비 유저 라벨링은 도메인 지식으로 판단. 
    - 헤비 유저의 정의 : LTV가 높음 x 플레이 타임이 긺 x 스테이지 진행도가 높음
    - 따라서, LTV 수익 분포의 상위 유저 중, 플레이 타임 길고 스테이지 진행도가 높은 유저를 헤비 유저로 선정하여, 라벨링한다.
    - 라벨링한 헤비 유저들의 특성을 기초 통계표로 1차 확인. (해당 게임에 대한 도메인 지식으로 판단)


## 4. 예측과 학습을 위해 사용되는 데이터 
    - 우리의 목표는 초기 스테이지 데이터만으로, 헤비 유저를 예측하는 모델을 만드는 것. 
    - 우리는 스테이지 10까지만의 데이터로, 이 유저가 헤비 유저가 될 가능성이 있는 지 없는 지를 판단하고 싶음.
    - 따라서, X 설명 변수에는 초기 스테이지, 초기 기간에서만 알 수 있는 데이터만을 참고로 함.
    

## 5. X 설명 변수
    - 초기 스테이지, 초기 기간에서만 알 수 있는 데이터들로 구성됨. 초기 데이터만 가지고, Y를 예측할 수 있어야 하기 때문.
    - 어떤 변수를 넣어야, Y를 잘 설명할 수 있을까?
        - 몰입의 강도 : "몇 분 했냐"보다 "어떻게 했냐"를 설명하는 변수들. 
            - 첫 세션 지속 시간, 두 번째 세션 지속시간, 설치 당일 총 플레이타임(설치한 후, 24시간, day1_total_playtime), 세션 횟수 (설치한 후, 24시간 내, day1_session_count), 첫번째 세션과 두 번째 세션의 시간간격(session_interval_1_2), 두번째 세션과 세번째 세션의 시간간격(session_interval_2_3)
            
        - 실력의 질 : 헤비 유저는 초반부터 게임에 대한 이해도가 다른 경우가 있음.
            - 스테이지별 클리어 소모 시간 (스테이지1부터 10, 버전별 정규화 필요)
            - 만약, 학습 데이터에서 비 헤비 유저가 

        -> 결측치를 어떻게 처리할 것인지의 문제. 
        - 1. 스테이지 클리어 타임이 Null -> 해당 스테이지에 도달하지 못하거나, 클리어하지 못한 채로 이탈 -> 아주 큰 값으로 채워넣음. -> 시간이 무한대로 걸렸다는 뜻으로 패널티 부여
        - 2. 세션 간격이 Null -> 안 돌아옴 -> 아주 큰 값으로 채워넣음 -> 돌아오는 데 무한대의 시간이 걸렸다는 뜻.
        - 3. 세션 지속시간 -> 플레이 안 함 -> 0 값으로 채워 넣음.
        --> (대안1) 또는 최신 트리모델에서는 Null을 데이터 자체로 사용할 수 있으므로, 결측치 처리 없이 그대로 학습시키는 방안 채택.

## 6. 피쳐 엔지니어

### 6-1. 피쳐 정규화 (공변량의 문제)
    - 버전마다, 스테이지별 난이도가 상이할 수 있음. 따라서 스테이지별 클리어타임과 같이 버전별로 영향을 받는 변수에 대해서는 정규화하여, 버전 내에서의 비교 단위로 학습.

### 6-2.미래 정보를 제한한 피쳐 추가 (난이도 무관 변수)
    - 버전별로 난이도가 다른 것을 방지하기 위한 방법으로써, 버전별로 난이도를 무시한 피쳐를 추가.
    - (개선 사항2) 어떤 피쳐를 넣으면 좋지?
    - Current_Attempt, Failure_count, Move_Count, 

### 6-3. (개선사항2) 피쳐 엔지니어링이 끝난 후, 피쳐별 분포와 상관관계 확인? EDA를 어떻게 할 것인지.
- 진짜 헤비 유저와, 헤비 유저가 아닌 그룹으로 나눔.
- 각 변수의 분포에서 확인.
- 두 그룹의 분포가 확연하게 다름 -> 좋은 설명변수. 두 그룹의 분포가 거의 겹쳐 있음 -> 좋지 않은 설명변수.
- 변수의 상관관계 히트맵 확인.

## 7. 평가 매트릭스
    - 재현율 : 실제 정답인 것 중 모델이 찾아낸 비율 (제2종 오류를 줄임)
    - 정밀도 : 모델이 "그렇다"라고 예측한 것 중 실제 정답인 비율 (제1종 오류를 줄임)
    - F1 Score : 재현율과 정밀도의 조화평균
    - 비지니스 맥락에서 헤비 유저를 발견하지 못했을 때의 리스크가, 헤비 유저를 잘못 발견했을 때의 리스크보다 더욱 크기에, 제 2종 오류룰 최소화하기 위해 학습시, 재현율을 높이는 것으로 평가 매트릭스를 설정한다.
    - 그러나, 모델의 전체적인 성능을 판단하기 위해, 오차 행렬로 재현율과 정밀도를 동시에 확인하며 참고할 것임.
    - 모델 평가 : 0.25, 0.26 버전의 데이터로 학습 후, 0.27 버전의 데이터에 수작업으로 라벨링한 뒤, 0.27과 0.29 데이터로 모델을 평가. 재현율이 높아야 하며, 정밀도는 낮아도 괜찮음.

## 8. 훈련 데이터와 테스트 데이터
    - 훈련 데이터 : 0.25의 80%, 0.26의 80% 
    - 테스트 데이터1 : 0.25의 20%, 0.26의 20% <- 동일 모델 상에서 잘 예측하고 있는 지를 확인 
    - 테스트 데이터2 : 0.27, 0.29 <- 다른 버전에서도 잘 예측되는 지를 확인 

### 9. 분할 비율
    - 훈련 데이터에서는 헤비 유저와 비 헤비 유저의 비율을 1:1로 맞춘다. (언더 샘플링 or 오버 샘플링)
    - 표본의 헤비 유저와 비 헤비 유저의 비율이 95:5 정도로 큰 차이가 존재한다. 이대로 학습하면, 데이터 불균형 문제로 인해, 다수 클래스를 우선적으로 예측하게 되어, 소수 클래스에 대한 성능이 저하될 수 있다.
    - 따라서 언더 샘플링, 오버 샘플링 두 개의 방법을 둘 다 채용해서 학습해본다.
    - 언더 샘플링 : 무작위 언더샘플링
    - 오버 샘플링 : 무작위 오버 샘플링과 SMOTE 방법을 채택
        - SMOTE : 기존 소수 클래스의 데이터를 바탕으로 새로운 데이터를 합성하는 방법. 소수 클래스와 다른 소수 클래사의 인스턴스의 특성 차이를 기반으로 새로운 인스턴스 생성.
        - SMOTE의 특징 : 양성으로 예측하는 비율이 높아지기 때문에, 정밀도는 감소하지만, 재현율은 증가하게 됨(우리의 모델 목적과 동일)

## 10. 모델 선정
    - 모델 : XGBoost, RandonForest
    - 이유 : 바이너리 클래시피케이션에서 XGBoost가 빠르고, RandonForest가 정확도가 높음.
    - 결과 디멘션으로는 1. 데이터 분할 방법 3개(무작위 언더 샘플링, 무작위 오버 샘플링, SMOTE 방법) x 2. 모델 2개(XGBoost, Randomfore) x 다른 데이터로 인한 모델 평가 2가지 (0.27, 0.29) = 12 종류에 대한 오차행렬을 파악하게 된다.
    - 이들 중, 재현율이 높고, 제1종 오류의 발생건수 또한 어느 정도 큰 모델을 선택한다. (잠재적 포텐 유저를 찾는 것이 목적이기 때문에.)


## 11. 기대 결과
    - 모델이 어떤 버전이든 헤비 유저를 잘 예측할 수 있을 것을 기대. 특히, 제 2종 오류 발생률이 낮음.
    - 대신 제 1종 오류가 발생하여, 해당 타이틀에서 헤비 유저는 아니지만, 헤비 유저로 예측된 유저가 발생할 수 있음.
    - 이러한 유저들을 어떻게 해석할 것인가?
        - 모델은 이러한 유저들이 헤비 유저라고 판단하였음. 즉, 헤비 유저와 동일한 특성을 가진 유저들이지만, 헤비 유저가 아니었음. 이러한 유저들을 잠재적 헤비 유저라고 판단할 수 있음.

# 이 모델 사용 방법 : 헤비 유저 이탈 보조 지표로써 사용 가능
    - 잠재적 헤비 유저 : 모델이 헤비 유저라고 판단한 유저 (헤비 유저의 특성을 가지고 있는 유저)
    - 잠재적 헤비 유저의 헤비 유저로의 전환율 (실제로 헤비 유저가 된 유저들의 수/잠재적 헤비 유저의 수)를 통해, 헤비 유저의 이탈률을 추론할 수 있음.
    - 예를 들어, 0.25 버전에서 헤비 유저로의 전환률이 10%이고, 새롭게, 0.26 버전에서는 헤비 유저로의 전환률이 동일하게 10%라면, 버전을 업데이트 했더라도, 헤비 유저에 대한 영향은 미미하다고 판단할 수 있음.
    - 이 모델을 개발하게 된 배경은 다음과 같음.
        1. 업데이트시 어떠한 변경이 있든 간에, (스테이지의 배열을 어렵게 한다던가, 스테이지의 배열을 쉽게 한다던가) 헤비 유저나 라이트 유저는 그 변경에 대해서 다르게 영향을 받는다.
        2. 다수의 라이트 유저와 소수의 헤비 유저, 둘 다 수익에 큰 영향을 미치기에, 두 그룹 다 고려해야 한다.
        3. 가령, 스테이지의 배열이 쉽게 바꿔서, 라이트 유저의 게임 플레이가 원활하게 되어, 라이트 유저 간의 이탈률이 감소하더라도, 헤비 유저의 이탈률이 증가하면, 스테이지의 배열을 쉽게 바꾼 것이 오히려, 장기적 수익 측면에서 손해일 수 있다.
        4. 반대로, 스테이지의 배열을 어렵게 바꿔서 헤비 유저에게는 이득을, 라이트 유저에게 손해가 되는 경우, 헤비 유저의 이탈률이 감소하더라도, 라이트 유저의 이탈률이 증가하면, 스테이지의 배열을 어렵게 바꾼 것이 오히려, 장기적 수익 측면에서 손해일 수 있다.
        5. 특히, 라이트 유저의 경우, 영향을 단기간에 빠르게 받기 때문에, 바로 결과가 보일 수 있지만, 헤비 유저 이탈에 의한 손실은 단기적으로 보이지 않고, 장기적인 시간이 지난 후에야 보일 수 있다. 이는 우리의 일주일마다 빠른 템포로 AB 테스트를 진행하는 것과 맞지 않는다. 
        6. 일주일과 같이 빠른 속도로 A／B 테스트를 진행하면서 동시에, 헤비 유저가 이탈하는지 이탈하지 않는 지를 추정하며 관찰하는 것이, 그나마 우리가 어떠한 업데이트를 하였을 때, 단기적인 수익 개선 외에 장기적인 수익 개선 또한 예측 가능해진다.
        7. (개선사항 3)잠재적 헤비 유저들을 어떻게 트래킹할 것인지? 그리고 어느 시점에서 잠재적 헤비 유저가 헤비 유저로 전환될 것인지를 어떻게 판단할 것인지?
            -> 예측된 잠재적 헤비 유저들이 설치일로부터 7일 또는 14일이 지난 시점에서 실제로 헤비 유저를 달성한 사람이 몇 명인지를 카운트.
            -> LTV, 플레이타임 분포에서 잠재적 헤비 유저들이 어디에 속해있는 지를 판단해서 카운트하면 됨.
            -> 만약 릴리즈 Day 1의 잠재적 헤비 유저 10명 중, 일주일의 시간이 지난 시점에서 6명이 헤비 유저 조건(LTV 상위)를 달성했다면, 전환율 60%.
            -> 코호트 분석 형태로 정리. 특정 날짜에 설치한 유저들을 묶고, 모델이 코호트 날짜 기준 잠재적 헤비 유저를 지목. 일주일 또는 2주일 동안 게임을 즐기게 냅둠. 그 후, 100명 중 실제로 헤비 유저 조건을 달성한 사람을 확인.
            -> 헤비 유저 전환률 외의 비전환률에 해당하는 유저들의 정보 또한 확인해서, 어느 지점에서 이탈하였는지, 즉 잠재적 헤비 유저가 게임을 떠났다면, 왜 떠났는지 또한 분석 가능. (미전환 유저 분석)
        8. 이를 통해, 새로운 버전을 릴리즈하였을 때, 잠재적 헤비 유저의 전환률을 비교하여, 새로운 버전의 헤비 유저에 대한 영향력을 추론할 수 있음.

    - 보조지표 예시 : 헤비 유저 전환률 최소 유지 이상 + 초기 리텐션률 증가 -> 수익 확대

# 기타 : 해당 프로젝트를 진행하며 했던 질문들
1. 잠재적 헤비 유저들을 어떻게 트래킹할 것인지? 그리고 어느 시점에서 잠재적 헤비 유저가 헤비 유저로 전환될 것인지를 어떻게 판단할 것인지?