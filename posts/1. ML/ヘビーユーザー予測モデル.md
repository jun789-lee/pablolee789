# 初期プレイデータのみで長期的ヘビーユーザーを予測するモデルを作ってみよう

## 1. 選定ゲーム：tetrapiece（他のゲームに対してもヘビーユーザーを予測したい場合は、そのゲーム専用のモデルを新たに設計して学習させる必要がある）

## 2. 保有データ
- tetrapieceの各OS別・バージョン別データ。iOS 0.25～0.29、Android 0.25～0.29

## 3. 結果変数：ヘビーユーザーかどうか、0と1で判定
### 3-1. ラベリング：学習データのためのヘビーユーザーラベリングはドメイン知識で判断
    - ヘビーユーザーの定義：LTVが高い × プレイタイムが長い × ステージ進行度が高い
    - したがって、LTV収益分布の上位ユーザーの中で、プレイタイムが長くステージ進行度が高いユーザーをヘビーユーザーとして選定し、ラベリングする
    - ラベリングしたヘビーユーザーの特性を基礎統計表で1次確認（該当ゲームに対するドメイン知識で判断）


## 4. 予測と学習に使用されるデータ
    - 我々の目標は初期ステージデータのみでヘビーユーザーを予測するモデルを作ること
    - ステージ10までのデータのみで、このユーザーがヘビーユーザーになる可能性があるかどうかを判断したい
    - したがって、X説明変数には初期ステージ、初期期間でのみ分かるデータのみを参照する


## 5. X説明変数
    - 初期ステージ、初期期間でのみ分かるデータで構成される。初期データのみでYを予測できる必要があるため
    - どの変数を入れれば、Yをうまく説明できるか？
        - 没入の強度：「何分プレイしたか」より「どのようにプレイしたか」を説明する変数
            - 最初のセッション持続時間、2回目のセッション持続時間、インストール当日の総プレイタイム（インストール後24時間、day1_total_playtime）、セッション回数（インストール後24時間以内、day1_session_count）、1回目と2回目のセッション間隔（session_interval_1_2）、2回目と3回目のセッション間隔（session_interval_2_3）

        - 実力の質：ヘビーユーザーは序盤からゲームへの理解度が異なる場合がある
            - ステージ別クリア所要時間（ステージ1から10、バージョン別正規化が必要）
            - もし、学習データで非ヘビーユーザーが

        -> 欠損値をどのように処理するかの問題
        - 1. ステージクリアタイムがNull -> 該当ステージに到達していないか、クリアできずに離脱 -> 非常に大きな値で埋める -> 時間が無限大かかったという意味でペナルティ付与
        - 2. セッション間隔がNull -> 戻ってこなかった -> 非常に大きな値で埋める -> 戻るのに無限大の時間がかかったという意味
        - 3. セッション持続時間 -> プレイしなかった -> 0値で埋める
        --> （代案1）または最新のツリーモデルではNullをデータ自体として使用できるので、欠損値処理なしでそのまま学習させる方案を採用

## 6. フィーチャーエンジニアリング

### 6-1. フィーチャー正規化（共変量の問題）
    - バージョンごとにステージ別難易度が異なる可能性がある。したがって、ステージ別クリアタイムのようにバージョンごとに影響を受ける変数については正規化して、バージョン内での比較単位で学習

### 6-2. 未来情報を制限したフィーチャー追加（難易度無関係変数）
    - バージョンごとに難易度が異なることを防ぐための方法として、バージョンごとの難易度を無視したフィーチャーを追加
    - （改善事項2）どのフィーチャーを入れると良いか？
    - Current_Attempt、Failure_count、Move_Count

### 6-3.（改善事項2）フィーチャーエンジニアリング完了後、フィーチャー別分布と相関関係を確認？EDAをどのように行うか
- 実際のヘビーユーザーと、ヘビーユーザーではないグループに分ける
- 各変数の分布で確認
- 2つのグループの分布が明確に異なる -> 良い説明変数。2つのグループの分布がほぼ重なっている -> 良くない説明変数
- 変数の相関関係ヒートマップを確認

## 7. 評価メトリクス
    - 再現率：実際の正解の中でモデルが見つけ出した割合（第2種過誤を減らす）
    - 精度：モデルが「そうだ」と予測したものの中で実際の正解の割合（第1種過誤を減らす）
    - F1スコア：再現率と精度の調和平均
    - ビジネスの文脈でヘビーユーザーを発見できなかった時のリスクが、ヘビーユーザーを誤って発見した時のリスクより大きいため、第2種過誤を最小化するために学習時、再現率を高めることで評価メトリクスを設定する
    - しかし、モデルの全体的な性能を判断するために、混同行列で再現率と精度を同時に確認しながら参考にする
    - モデル評価：0.25、0.26バージョンのデータで学習後、0.27バージョンのデータに手作業でラベリングした後、0.27と0.29データでモデルを評価。再現率が高くなければならず、精度は低くても構わない

## 8. 訓練データとテストデータ
    - 訓練データ：0.25の80%、0.26の80%
    - テストデータ1：0.25の20%、0.26の20% <- 同一モデル上でうまく予測しているかを確認
    - テストデータ2：0.27、0.29 <- 他のバージョンでもうまく予測できるかを確認

### 9. 分割比率
    - 訓練データではヘビーユーザーと非ヘビーユーザーの比率を1:1に合わせる（アンダーサンプリング or オーバーサンプリング）
    - 標本のヘビーユーザーと非ヘビーユーザーの比率が95:5程度で大きな差がある。このまま学習すると、データ不均衡問題により、多数クラスを優先的に予測するようになり、少数クラスに対する性能が低下する可能性がある
    - したがって、アンダーサンプリング、オーバーサンプリングの2つの方法を両方採用して学習してみる
    - アンダーサンプリング：ランダムアンダーサンプリング
    - オーバーサンプリング：ランダムオーバーサンプリングとSMOTE方法を採用
        - SMOTE：既存の少数クラスのデータを基に新しいデータを合成する方法。少数クラスと他の少数クラスのインスタンスの特性差を基に新しいインスタンスを生成
        - SMOTEの特徴：陽性と予測する比率が高くなるため、精度は低下するが、再現率は増加する（我々のモデル目的と同一）

## 10. モデル選定
    - モデル：XGBoost、RandomForest
    - 理由：バイナリ分類でXGBoostが速く、RandomForestが精度が高い
    - 結果ディメンションとしては 1. データ分割方法3つ（ランダムアンダーサンプリング、ランダムオーバーサンプリング、SMOTE方法）× 2. モデル2つ（XGBoost、RandomForest）× 異なるデータによるモデル評価2種類（0.27、0.29）= 12種類に対する混同行列を把握することになる
    - これらの中で、再現率が高く、第1種過誤の発生件数もある程度多いモデルを選択する（潜在的ポテンシャルユーザーを見つけることが目的のため）


## 11. 期待結果
    - モデルがどのバージョンでもヘビーユーザーをうまく予測できることを期待。特に、第2種過誤発生率が低い
    - 代わりに第1種過誤が発生して、該当タイトルでヘビーユーザーではないが、ヘビーユーザーと予測されるユーザーが発生する可能性がある
    - このようなユーザーをどのように解釈するか？
        - モデルはこのようなユーザーをヘビーユーザーと判断した。つまり、ヘビーユーザーと同一の特性を持つユーザーだが、ヘビーユーザーではなかった。このようなユーザーを潜在的ヘビーユーザーと判断できる

# このモデルの使用方法：ヘビーユーザー離脱補助指標として使用可能
    - 潜在的ヘビーユーザー：モデルがヘビーユーザーと判断したユーザー（ヘビーユーザーの特性を持っているユーザー）
    - 潜在的ヘビーユーザーのヘビーユーザーへの転換率（実際にヘビーユーザーになったユーザー数/潜在的ヘビーユーザー数）を通じて、ヘビーユーザーの離脱率を推論できる
    - 例えば、0.25バージョンでヘビーユーザーへの転換率が10%で、新たに0.26バージョンでもヘビーユーザーへの転換率が同様に10%なら、バージョンをアップデートしても、ヘビーユーザーへの影響は軽微だと判断できる
    - このモデルを開発した背景は以下の通り
        1. アップデート時にどのような変更があっても（ステージの配列を難しくするとか、ステージの配列を簡単にするとか）、ヘビーユーザーやライトユーザーはその変更に対して異なる影響を受ける
        2. 多数のライトユーザーと少数のヘビーユーザー、両方とも収益に大きな影響を与えるため、両グループとも考慮すべきである
        3. 例えば、ステージの配列を簡単に変えて、ライトユーザーのゲームプレイが円滑になり、ライトユーザー間の離脱率が減少しても、ヘビーユーザーの離脱率が増加すれば、ステージの配列を簡単に変えたことがむしろ長期的収益面で損害かもしれない
        4. 反対に、ステージの配列を難しく変えてヘビーユーザーには利益を、ライトユーザーには損害となる場合、ヘビーユーザーの離脱率が減少しても、ライトユーザーの離脱率が増加すれば、ステージの配列を難しく変えたことがむしろ長期的収益面で損害かもしれない
        5. 特に、ライトユーザーの場合、影響を短期間で素早く受けるため、すぐに結果が見えるが、ヘビーユーザー離脱による損失は短期的には見えず、長期的な時間が経過した後にやっと見えることがある。これは我々の週ごとの速いテンポでA/Bテストを進めることと合わない
        6. 週のような速いスピードでA/Bテストを進めながら同時に、ヘビーユーザーが離脱するかしないかを推定しながら観察することが、せめて我々がどのようなアップデートをした時、短期的な収益改善以外に長期的な収益改善も予測可能になる
        7.（改善事項3）潜在的ヘビーユーザーをどのようにトラッキングするか？そしてどの時点で潜在的ヘビーユーザーがヘビーユーザーに転換するかをどのように判断するか？
            -> 予測された潜在的ヘビーユーザーがインストール日から7日または14日が経過した時点で実際にヘビーユーザーを達成した人が何人かをカウント
            -> LTV、プレイタイム分布で潜在的ヘビーユーザーがどこに属しているかを判断してカウントすればよい
            -> もしリリースDay 1の潜在的ヘビーユーザー10人中、1週間が経過した時点で6人がヘビーユーザー条件（LTV上位）を達成したなら、転換率60%
            -> コホート分析形態で整理。特定の日付にインストールしたユーザーをまとめ、モデルがコホート日付基準で潜在的ヘビーユーザーを指名。1週間または2週間ゲームを楽しませる。その後、100人中実際にヘビーユーザー条件を達成した人を確認
            -> ヘビーユーザー転換率以外の非転換率に該当するユーザーの情報も確認して、どの地点で離脱したか、つまり潜在的ヘビーユーザーがゲームを離れたなら、なぜ離れたかも分析可能（非転換ユーザー分析）
        8. これを通じて、新しいバージョンをリリースした時、潜在的ヘビーユーザーの転換率を比較して、新しいバージョンのヘビーユーザーへの影響力を推論できる

    - 補助指標例：ヘビーユーザー転換率最小維持以上 + 初期リテンション率増加 -> 収益拡大

# その他：このプロジェクトを進めながらした質問
1. 潜在的ヘビーユーザーをどのようにトラッキングするか？そしてどの時点で潜在的ヘビーユーザーがヘビーユーザーに転換するかをどのように判断するか？
