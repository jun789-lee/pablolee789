# 헤비 유저 세그멘트의 초기 스테이지 행동 패턴 분석

## 배경
- 몰입과 지루함의 밸런스 
- 초기 스테이지의 이탈률이 높아서, 초기 스테이지의 난이도를 조절해서 이탈률을 낮추고자 하는 방안을 실시하려고 한다.
- 이 때, 이러한 방안을 실시할 때, 이득을 보는 유저층과 손해를 보는 유저층은 어디인가?
- 이득을 보는 유저층은 라이트 유저, 초보 유저이겠고, 손해를 보는 유저층은 헤비 유저, 고수 유저일 것이다. 헤비 유저가 초기 스테이지의 난이도를 쉽게 했을 때, 지루함을 느낀다면, 이탈해버릴 것이고, 이로 인해, 게임의 장기적 LTV는 감소하게 될 것이다.
- 따라서, 초기 스테이지의 난이도를 쉽게 하는 방안을 적용하기 위해서는 헤비 유저가 초기 스테이지의 난이도를 쉽게 했을 때, 얼마나 지루함을 느끼는 지(다른 말로는 얼마나 이탈하는 지)를 파악할 필요가 있다. 만약, 헤비 유저가 초기 스테이지에서 이탈하지 않는다면, 초기 스테이지의 난이도를 쉽게 하는 것이 유효하다.

## 실험의 설계
- 이상적인 실험의 설계는 유저들에게 중간 중간 어려운 난이도의 스테이지가 존재하는 게임을 먼저 플레이하게 한 뒤, 헤비 유저들을 선별한다. 그 후, 그룹의 유저들의 기억을 지우고, 난이도를 쉽게 만든 버전의 게임을 다시 플레이하게 해서, 헤비 유저들이 난이도가 쉬운 초기 스테이지에서 이탈하는 지, 이탈하지 않는 지를 확인하는 것이다.

- 하지만, 이러한 실험은 불가능하다. 유저의 기억을 지우는 것이 현실의 기술로 가능한지도 의문이고, 가능한다고 한들 윤리적인 문제로 인해, 이러한 실험은 불가능하다.

- 다른 한계점은 우리가 갖고 있는 데이터이다. 데이터는 버전이 0.25, 0.26, 0.27, 0.28, 0.29로 구성되어 있다. 그리고 각 버전별로 스테이지의 배열 순서와 난이도가 다르다. 따라서 스테이지 3이 0.25에서는 어려웠지만, 0.28에서는 어려울 수도 있다.

- 정리하자면, 첫번째 문제는, 우리가 원하는 완전히 통제된 실험을 실시할 수 없다는 것이고, 두번째 문제로는 실험을 실시하기에 어려운 데이터라는 것이다.

- 위의 문제를 최대한 극복하기 위해 나는 다음과 같은 방법을 채택하였다.
1. 정규화
- 버전별로 스테이지의 배열 순서와 난이도가 다르기 때문에, 데이터를 그대로 사용하면 다음과 같은 문제가 발생할 수 있다. 예를 들어, 0.25 버전에서 스테이지 3이 어려워서 평균적으로 60초 걸렸다고 가정하자. 헤비 또는 고수 유저의 경우, 30초 안에 클리어하여, 평균적으로 더 빨리 스테이지를 클리어를 했다고 가정하자. 이번에는 0.28 버전에서 스테이지 3이 쉬워져서, 평균적으로 30초가 걸리고, 헤비 유저는 15초가 걸렸다고 하자. 모델이 만약, 0.25 버전으로 학습하여, 30초의 클리어타임이 헤비 유저라고 판단한다면, 0.28 버전에서는 평균적으로 30초가 걸리는 유저를 헤비 유저로 판단하게 될 것이다.
- 이를 방지하기 위해서, 클리어타임을 Z 정규화를 통해, 평균으로부터 얼마나 떨어져 있는 지로 변환한다. Z-Score를 통해, 각 버전별 스테이지의 배열 순서와 난이도가 다르더라도, 이 문제를 조금 해결할 수 있을 거라 생각한다.
- 또한, 버전별 스테이지의 배열 순서와 난이도의 차이에 영향을 많이 받지 않는, 세션별 플레이 타임과 같은 변수 또한 추가할 예정이다. (이 또한 정규화하는 게 좋은가? -> 정규분포를 따르지 않을 확률이 높으므로 로그변환 후 정규화 하라는데, 그 이유가 무엇인가? -> )

2. 헤비유저의 선별 -> 잠재적 헤비 유저들의 재선별 -> 
- 가장 먼저, 헤비 유저의 고유의 특징들을 추출한다. 이는 우리가 알고 있는 도메인 지식을 활용하여도 좋고, 데이터 자체의 분포를 확인하여, 이상치들을 추출하는 방법도 있다. (도메인 지식으로 라벨링)

- 선별된 유저들에게는 헤비 유저라는 라벨을 부여한다. 그 후, 학습을 통해 머신러닝으로 잠재적 헤비 유저들을 재선별한다. 이 때 모델의 평가는 오차 매트릭스를 사용하되, 제 1종 오류(헤비 유저인데, 헤비 유저가 아니라고 판단하는 경우)를 최소화한다. 이유는, 잠재적 헤비 유저를 선별하기 위해서이다. 이를 통해, 훈련셋을 통해, 잠재적 헤비 유저를 선별하는 모델을 학습한 뒤, 테스트셋을 통해, 모델의 일반적인 성능 또한 평가한다. 

- 모델이 어느 정도 기준치를 넘는 성능을 보여주게 된다면, 이 모델을 활용하여, 새로운 데이터셋의 잠재적 헤비 유저들을 선별한 후, 잠재적 헤비 유저의 전환률을 측정한다. 

# AB 테스트의 설계
- 학습된 모델을 바탕으로 기존의 오리지널 모델과, 난이도를 쉽게 배치한 새로운 모델을 동시에 배포하여, 잠재적 헤비 유저들의 이탈률을 측정하고 A/B 테스트를 실시한다. 만약, 쉬운 버전의 잠재적 헤비 유저들의 이탈률의 차이가 없고, 라이트 유저들의 이탈률이 낮아져, 전체적인 이탈률이 낮아진다면, 스테이지를 쉽게 배열하는 것이 더욱 좋은 선택이 된다.
-> 시간 관계상, AB 테스트를 과제 제출 기간까지 하는 것은 어려웠다. 이는 추후 결과를 내 블로그에 올려놓을테니, 그쪽에 확인해주길 바람.

---

## 데이터 준비

### 1. 데이터 범위
- 타이틀 A의(iOS, Android) 버전 0.25~0.29의 데이터.

#### 1-1. 대상
- tetrapiece의 0.25 Android, iOS와 0.26의 Android, iOS

#### 2-1. 피쳐 엔지니어링
- 어떠한 설명변수를 채택할 것인가?
- 유저를 구성하는 지표들은 여러 가지가 존재한다. 토탈 플레이타임, 세션별 평균 플레이타임, 세션 2회차 3회차 4회차 리텐션률, 세션간 간격, 스테이지 리텐션률, LTV, 각 스테이지별 클리어 타임, 섹션 1에서의 도달 스테이지, 섹션 2에서의 도달 스테이지 등. 
- 설명 변수를 선택할 때 주의해야 할 점이 있다.
1. 미래의 정보를 포함하고 있지 않아야 한다.
- 

#### 2-2. 헤비 유저를 어떻게 정의하고, 어떠한 기준으로 라벨링할 것인가?
- LTV를 통해, 먼저 수익에 큰 기여를 하고 있는 유저들을 1차적으로 선별한다. 
- 그 후, 1차적으로 선별된 유저 중, 최대 도달 스테이지가 높고, 토탈 플레이 타임이 긴 유저들을 위주로 선정한다. 라벨링을 할 때는, 토탈 플레이타임, max_stage, LTV와 같은 정보를 활용하여 라벨링을 한다.
- 학습할 때나 예측할 때는, 과거/초반 정보만 써야 한다. 최대 도달 스테이지, 토탈 플레이 타임,  세션 횟수와 같이 미래의 정보를 반영하는 변수는 포함하지 않는다.

- 이렇게 헤비 유저의 정의가 끝나고 라벨링이 가능하게 되었다.

#### 2-3. 피쳐 정규화
- 이렇게 해서 버전별 스테이지의 난이도가 다른 것의 영향을 고려할 수 있게 되었다.



### 3. 헤비 유저 검증 및 변수 선택
- 위의 가정을 뒷받침할 근거로, 헤비 유저로 선정된 유저들의 플레이 타임과, 세션 횟수, 최대 도달 스테이지 분포에서 상위권에 포함되어 있는지를 확인한다.
- 개인고정효과를 줄이기 위하여, 국가, OS별로 세그멘트, 디멘션을 나눠서 비교한다.
- 분포에서 분포적 차이가 존재하는지를 확인한 뒤, 존재한다면, 설명변수의 더미변수로써 넣는다.

#### 3-1. X변수 선택의 문제
- 플레이 타임을 변수에 넣는 것이 타당한가?
- 0.27과 0.28에서 새로운 버전에서 테스트를 할 때, 토탈 플레이타임과 같은 값들은 0이나, 매우 작은 값들로 되어 있을 것이다. **미래의 정보를 포함하고 있기 때문이다.**
- **해결책**: 초기 N분, 초기 N 스테이지까지의 행동 데이터로 한정해야 한다.

#### 3-2. 공변량 변화의 문제 (Covariate Shift)
- 모델을 0.25(어려운 버전)에서 학습했다고 치자. 이 때 헤비 유저의 특성이 스테이지1을 30초만에 깼다고 치자.
- 그런데, 0.26이 난이도가 더 쉬워졌고 0.26(쉬운 버전)의 데이터를 넣어서 같이 학습하게 되면, 스테이지가 쉬워져서 30초만에 클리어한 것인데, 모델은 헤비 유저로 예측할 가능성이 생긴다.

**해결책 1: Z-Score 변환 (버전별 정규화)**
1. 데이터를 버전별(0.25, 0.26...)로 쪼갠다.
2. 각 버전 안에서 클리어 타임, 점수, 사망 횟수 등의 수치형 데이터의 평균(μ)과 표준편차(σ)를 구한다.
3. 모든 유저의 데이터를 Z-Score로 변환한다.
   - 이제 0.25의 1스테이지 데이터와 0.29의 1스테이지 데이터는 비교 가능해진다.

**해결책 2: 난이도 무관 변수 (Invariant Features) 추가**
- Z-Score로도 불안하다면, 난이도와 아예 상관없는 변수 비중을 높인다.
  - 세션 당 평균 길이
  - 세션과 세션 간의 평균 시간 차이
  - 일일 접속 횟수
  - 광고 시청 횟수
  - 설정 버튼 클릭
  - 상점 조회 횟수 등

---

### 4. 헤비 유저 기초 통계 확인
- 헤비 유저로 선정된 유저들의 기초 통계표를 확인한다.
- **헤비 유저의 선정 기준**: LTV가 높은 유저들 중, 정해진 기간 내의 플레이타임과 최대 스테이지 도달이 높은 유저들. (고수익, 고플레이)

---

### 5. 레이블 부여
- 전체 데이터셋에서 헤비 유저에 해당하는 유저에게 값을 부여한다.
  - `IsHeavyUser = 1` (헤비 유저)
  - `IsHeavyUser = 0` (비 헤비 유저)

---

### 6. 데이터 분할
- 전체 데이터셋의 80%를 트레이닝 데이터셋, 20%를 테스트 데이터셋으로 나눈다.

#### 6-1. 클래스 비율 처리
- **트레이닝**: 헤비 유저와 비 헤비 유저의 비율을 1:1로 맞춘다 (언더샘플링 or 오버샘플링)
- **테스트**: 헤비 유저와 비 헤비 유저의 비율을 현실 비율에 맞춘다 (실제 성능 평가를 위해)

---

## 모델 학습 및 평가

### 7. 모델 학습
- 트레이닝 데이터셋을 사용하여 모델을 학습한다.

---

### 8. 모델 성능 평가
- 테스트 데이터셋을 사용하여 모델의 성능을 평가한다.

#### 8-1. 평가 지표: 오차 행렬 (Confusion Matrix)
- **F1 스코어나 Recall 대신 오차 행렬을 채택한다.**
- 이유: 1종 오류(헤비 유저를 비헤비로 예측)와 2종 오류(비헤비를 헤비로 예측) **둘 다 중요**하기 때문이다.
- 오차 행렬을 통해 각 오류의 개수를 직접 확인하고, 비즈니스 맥락에서 어떤 오류가 더 치명적인지 판단한다.

#### 8-2. 참고: F1 스코어란?
- Precision과 Recall의 조화평균
- 1종 오류와 2종 오류를 균형 있게 고려할 때 사용

---

## 검증 및 적용

### 9. 0.27 버전에서 검증
- (4)에서 확인된 헤비 유저 기준의 기초 통계표에 해당하는 유저들을 0.27 버전에서 추출한다.

### 10. 실제 헤비 유저 여부 확인
- 해당 유저들의 플레이타임, 수익 분포를 확인하며, 실제 헤비 유저에 해당하는지를 확인한다.

### 11. 새 버전에 모델 적용
- 모델을 사용해서 0.27과 0.28 버전의 헤비 유저를 예측한다.

### 12. 예측 결과 분석
- 예측된 유저의 분포와 통계표를 확인한다.

---

## 요약: 핵심 포인트

> 여러 버전(0.25~0.27)을 섞어서 모델을 학습시킨다. 이제 모델은 **"스테이지가 어렵든 쉽든, 남들보다 월등히 잘하고(Z-Score 우수), 상점을 자주 보는 사람이 헤비 유저다"**라는 패턴을 배운다.없다.
- **결론**: 수익이 높은 유저 중, 초기 스테이지에서 벗어나, 최대 스테이지 도달도 높고, 플레이 타임도 긴 유저로 선정한다.

---

### 3. 헤비 유저 검증 및 변수 선택
- 위의 가정을 뒷받침할 근거로, 헤비 유저로 선정된 유저들의 플레이 타임과, 세션 횟수, 최대 도달 스테이지 분포에서 상위권에 포함되어 있는지를 확인한다.
- 개인고정효과를 줄이기 위하여, 국가, OS별로 세그멘트, 디멘션을 나눠서 비교한다.
- 분포에서 분포적 차이가 존재하는지를 확인한 뒤, 존재한다면, 설명변수의 더미변수로써 넣는다.

#### 3-1. X변수 선택의 문제
- 플레이 타임을 변수에 넣는 것이 타당한가?
- 0.27과 0.28에서 새로운 버전에서 테스트를 할 때, 토탈 플레이타임과 같은 값들은 0이나, 매우 작은 값들로 되어 있을 것이다. **미래의 정보를 포함하고 있기 때문이다.**
- **해결책**: 초기 N분, 초기 N 스테이지까지의 행동 데이터로 한정해야 한다.

#### 3-2. 공변량 변화의 문제 (Covariate Shift)
- 모델을 0.25(어려운 버전)에서 학습했다고 치자. 이 때 헤비 유저의 특성이 스테이지1을 30초만에 깼다고 치자.
- 그런데, 0.26이 난이도가 더 쉬워졌고 0.26(쉬운 버전)의 데이터를 넣어서 같이 학습하게 되면, 스테이지가 쉬워져서 30초만에 클리어한 것인데, 모델은 헤비 유저로 예측할 가능성이 생긴다.

**해결책 1: Z-Score 변환 (버전별 정규화)**
1. 데이터를 버전별(0.25, 0.26...)로 쪼갠다.
2. 각 버전 안에서 클리어 타임, 점수, 사망 횟수 등의 수치형 데이터의 평균(μ)과 표준편차(σ)를 구한다.
3. 모든 유저의 데이터를 Z-Score로 변환한다.
   - 이제 0.25의 1스테이지 데이터와 0.29의 1스테이지 데이터는 비교 가능해진다.

**해결책 2: 난이도 무관 변수 (Invariant Features) 추가**
- Z-Score로도 불안하다면, 난이도와 아예 상관없는 변수 비중을 높인다.
  - 세션 당 평균 길이
  - 세션과 세션 간의 평균 시간 차이
  - 일일 접속 횟수
  - 광고 시청 횟수
  - 설정 버튼 클릭
  - 상점 조회 횟수 등

---

### 4. 헤비 유저 기초 통계 확인
- 헤비 유저로 선정된 유저들의 기초 통계표를 확인한다.
- **헤비 유저의 선정 기준**: LTV가 높은 유저들 중, 정해진 기간 내의 플레이타임과 최대 스테이지 도달이 높은 유저들. (고수익, 고플레이)

---

### 5. 레이블 부여
- 전체 데이터셋에서 헤비 유저에 해당하는 유저에게 값을 부여한다.
  - `IsHeavyUser = 1` (헤비 유저)
  - `IsHeavyUser = 0` (비 헤비 유저)

---

### 6. 데이터 분할
- 전체 데이터셋의 80%를 트레이닝 데이터셋, 20%를 테스트 데이터셋으로 나눈다.

#### 6-1. 클래스 비율 처리
- **트레이닝**: 헤비 유저와 비 헤비 유저의 비율을 1:1로 맞춘다 (언더샘플링 or 오버샘플링)
- **테스트**: 헤비 유저와 비 헤비 유저의 비율을 현실 비율에 맞춘다 (실제 성능 평가를 위해)

---

## 모델 학습 및 평가

### 7. 모델 학습
- 트레이닝 데이터셋을 사용하여 모델을 학습한다.

---

### 8. 모델 성능 평가
- 테스트 데이터셋을 사용하여 모델의 성능을 평가한다.

#### 8-1. 평가 지표: 오차 행렬 (Confusion Matrix)
- **F1 스코어나 Recall 대신 오차 행렬을 채택한다.**
- 이유: 1종 오류(헤비 유저를 비헤비로 예측)와 2종 오류(비헤비를 헤비로 예측) **둘 다 중요**하기 때문이다.
- 오차 행렬을 통해 각 오류의 개수를 직접 확인하고, 비즈니스 맥락에서 어떤 오류가 더 치명적인지 판단한다.

#### 8-2. 참고: F1 스코어란?
- Precision과 Recall의 조화평균
- 1종 오류와 2종 오류를 균형 있게 고려할 때 사용

---

## 검증 및 적용

### 9. 0.27 버전에서 검증
- (4)에서 확인된 헤비 유저 기준의 기초 통계표에 해당하는 유저들을 0.27 버전에서 추출한다.

### 10. 실제 헤비 유저 여부 확인
- 해당 유저들의 플레이타임, 수익 분포를 확인하며, 실제 헤비 유저에 해당하는지를 확인한다.

### 11. 새 버전에 모델 적용
- 모델을 사용해서 0.27과 0.28 버전의 헤비 유저를 예측한다.

### 12. 예측 결과 분석
- 예측된 유저의 분포와 통계표를 확인한다.

---

## 요약: 핵심 포인트

> 여러 버전(0.25~0.27)을 섞어서 모델을 학습시킨다. 이제 모델은 **"스테이지가 어렵든 쉽든, 남들보다 월등히 잘하고(Z-Score 우수), 상점을 자주 보는 사람이 헤비 유저다"**라는 패턴을 배운다.