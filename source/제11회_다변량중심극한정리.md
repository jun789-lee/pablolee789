# 제11회 다변량 중심극한정리 (Multivariate Central Limit Theorem)

## 1. 복습: 다변량 정규분포

### 설정
$$\mathbf{X} \sim N(\boldsymbol{\mu}, \boldsymbol{\Sigma})$$

- $\boldsymbol{\mu} = (\mu_1, \mu_2)^T$: 평균 벡터
- $\boldsymbol{\Sigma} = \begin{pmatrix} \sigma_{11} & \sigma_{12} \\ \sigma_{12} & \sigma_{22} \end{pmatrix}$: 공분산 행렬

### 표준화 변환
$$\mathbf{Z} = A^{-1}(\mathbf{X} - \boldsymbol{\mu})$$

여기서 $\boldsymbol{\Sigma} = AA^T$이면, $\mathbf{Z} \sim N(\mathbf{0}, I_k)$

---

## 2. 양정치 행렬 (Positive Definite Matrix)

### 정의
$\boldsymbol{\Sigma}$가 양정치(positive definite)란:
$$\mathbf{a}^T \boldsymbol{\Sigma} \mathbf{a} > 0 \quad \text{for all } \mathbf{a} \neq \mathbf{0}$$

### 이차형식 (Quadratic Form)
$$\mathbf{a}^T \boldsymbol{\Sigma} \mathbf{a} = \sum_{i=1}^{k} \sum_{j=1}^{k} \sigma_{ij} a_i a_j$$

### 중요 성질
$\boldsymbol{\Sigma}$가 양정치일 때:
- $\boldsymbol{\Sigma} = AA^T$인 **비특이(non-singular)** 행렬 $A$ 존재
- $A$는 유일하지 않음 (예: Cholesky 분해)

### 증명
$$\mathbf{a}^T AA^T \mathbf{a} = (A^T \mathbf{a})^T (A^T \mathbf{a}) = \|A^T \mathbf{a}\|^2 \geq 0$$

---

## 3. Z-변환 (다변량)

### 가정
- $\mathbf{X} \sim N(\boldsymbol{\mu}, \boldsymbol{\Sigma})$
- $\boldsymbol{\Sigma}$는 양정치 행렬
- $\boldsymbol{\Sigma} = AA^T$인 평방근 행렬 $A$ 존재

### Z-변환
$$\mathbf{Z} = A^{-1}(\mathbf{X} - \boldsymbol{\mu})$$

### 결과
$$\mathbf{Z} \sim N(\mathbf{0}, I_k) \quad \text{(표준 다변량 정규분포)}$$

### MGF를 이용한 증명
$$E[e^{\mathbf{t}^T \mathbf{Z}}] = E[e^{\mathbf{t}^T A^{-1}(\mathbf{X} - \boldsymbol{\mu})}]$$

$\mathbf{s} = (A^{-1})^T \mathbf{t}$로 치환하면:
$$= e^{-\mathbf{s}^T \boldsymbol{\mu}} M_{\mathbf{X}}(\mathbf{s})$$
$$= e^{-\mathbf{s}^T \boldsymbol{\mu}} e^{\mathbf{s}^T \boldsymbol{\mu} + \frac{1}{2}\mathbf{s}^T \boldsymbol{\Sigma} \mathbf{s}}$$
$$= e^{\frac{1}{2}\mathbf{t}^T \mathbf{t}}$$

이것이 $N(\mathbf{0}, I_k)$의 MGF!

---

## 4. 기댓값 벡터와 분산 행렬

### 기댓값 벡터
$$E[\mathbf{X}] = \begin{pmatrix} E[X_1] \\ E[X_2] \\ \vdots \\ E[X_k] \end{pmatrix} = \boldsymbol{\mu}$$

### 분산 행렬 (공분산 행렬)
$$\text{Var}(\mathbf{X}) = E[(\mathbf{X} - \boldsymbol{\mu})(\mathbf{X} - \boldsymbol{\mu})^T] = \boldsymbol{\Sigma}$$

$(i, j)$ 성분:
$$\sigma_{ij} = \text{Cov}(X_i, X_j) = E[(X_i - \mu_i)(X_j - \mu_j)]$$

---

## 5. 선형변환의 기댓값과 분산

### 설정
$$\mathbf{Y} = B\mathbf{X} + \mathbf{b}$$

여기서:
- $B$: $m \times k$ 행렬 (상수)
- $\mathbf{b}$: $m \times 1$ 벡터 (상수)

### 기댓값
$$E[\mathbf{Y}] = E[B\mathbf{X} + \mathbf{b}] = BE[\mathbf{X}] + \mathbf{b} = B\boldsymbol{\mu} + \mathbf{b}$$

### 분산 행렬
$$\text{Var}(\mathbf{Y}) = B \cdot \text{Var}(\mathbf{X}) \cdot B^T = B \boldsymbol{\Sigma} B^T$$

> **핵심 공식:** $\text{Var}(B\mathbf{X}) = B \boldsymbol{\Sigma}_X B^T$

---

## 6. Z-변환 검증

### 기댓값 확인
$\mathbf{X} = A\mathbf{Z} + \boldsymbol{\mu}$에서:
$$E[\mathbf{X}] = E[A\mathbf{Z} + \boldsymbol{\mu}] = AE[\mathbf{Z}] + \boldsymbol{\mu} = \boldsymbol{\mu}$$

($E[\mathbf{Z}] = \mathbf{0}$이므로)

### 분산 확인
$$\text{Var}(\mathbf{X}) = E[(\mathbf{X} - \boldsymbol{\mu})(\mathbf{X} - \boldsymbol{\mu})^T]$$
$$= E[(A\mathbf{Z})(A\mathbf{Z})^T] = E[A\mathbf{Z}\mathbf{Z}^T A^T]$$
$$= A \cdot E[\mathbf{Z}\mathbf{Z}^T] \cdot A^T = A I_k A^T = AA^T = \boldsymbol{\Sigma}$$

---

## 7. 다변량 중심극한정리 (Multivariate CLT) ⭐

### 설정
- $\mathbf{X}$: 기댓값 벡터 $\boldsymbol{\mu}$, 분산 행렬 $\boldsymbol{\Sigma}$를 가지는 $k$-차원 확률벡터
- $\mathbf{X}_1, \mathbf{X}_2, \ldots, \mathbf{X}_N$: $\mathbf{X}$의 $N$개 **독립 복사본**

### 표본평균 벡터
$$\bar{\mathbf{X}}_N = \frac{1}{N}\sum_{i=1}^{N} \mathbf{X}_i$$

### 다변량 CLT
$$\sqrt{N}(\bar{\mathbf{X}}_N - \boldsymbol{\mu}) \xrightarrow{d} N(\mathbf{0}, \boldsymbol{\Sigma})$$

> **분포수렴(convergence in distribution)**

### 다변량 CLT의 의미 ⭐

**표본평균 벡터:**
$$\bar{\mathbf{X}}_N = \begin{pmatrix} \bar{X}^{(1)}_N \\ \bar{X}^{(2)}_N \\ \vdots \\ \bar{X}^{(k)}_N \end{pmatrix}$$

각 성분은 해당 변수의 N개 표본 평균:
- $\bar{X}^{(1)}_N$: 1번째 성분의 표본평균
- $\bar{X}^{(2)}_N$: 2번째 성분의 표본평균
- ...

**핵심 포인트:** 단순히 "각각 정규분포"가 아님!

| 약한 주장 | 강한 주장 (다변량 CLT) |
|----------|----------------------|
| $\bar{X}^{(1)} \sim N(\mu_1, ...)$ (개별) | **전체 벡터가 함께** 다변량 정규분포 |
| $\bar{X}^{(2)} \sim N(\mu_2, ...)$ (개별) | **상관관계($\boldsymbol{\Sigma}$)까지 유지!** |

**왜 중요한가?**

회귀분석에서 $\bar{X}$와 $\overline{XY}$의 **동시 분포**가 필요:
- 개별 정규분포만으로는 부족
- 둘의 **상관관계**까지 알아야 $\hat{\beta}$의 분포를 구할 수 있음

### 어떻게 상관관계가 유지되는가?

**극한 분포가 $N(\mathbf{0}, \boldsymbol{\Sigma})$!** ← $\boldsymbol{\Sigma}$에 상관관계 정보 포함

$$\boldsymbol{\Sigma} = \begin{pmatrix} \text{Var}(X^{(1)}) & \text{Cov}(X^{(1)}, X^{(2)}) \\ \text{Cov}(X^{(2)}, X^{(1)}) & \text{Var}(X^{(2)}) \end{pmatrix}$$

**구체적 증명:**

$$\text{Cov}(\bar{X}^{(1)}, \bar{X}^{(2)}) = \frac{1}{N}\text{Cov}(X^{(1)}, X^{(2)}) = \frac{\sigma_{12}}{N}$$

$\sqrt{N}$을 곱하면:
$$\text{Cov}(\sqrt{N}\bar{X}^{(1)}, \sqrt{N}\bar{X}^{(2)}) = \sigma_{12}$$

**원래 공분산이 그대로 유지됨!**

> **다변량 CLT = 각 성분 평균이 정규분포 + 극한 분포의 $\boldsymbol{\Sigma}$가 원래 공분산 유지!**

---

## 8. 1변량 CLT와의 비교

### 1변량 CLT
$X$: 기댓값 $\mu$, 분산 $\sigma^2$

$X_1, \ldots, X_N$: 독립 복사본

$$\sqrt{N}(\bar{X}_N - \mu) \xrightarrow{d} N(0, \sigma^2)$$

### 다변량 CLT
$\mathbf{X}$: 기댓값 $\boldsymbol{\mu}$, 공분산 $\boldsymbol{\Sigma}$

$\mathbf{X}_1, \ldots, \mathbf{X}_N$: 독립 복사본

$$\sqrt{N}(\bar{\mathbf{X}}_N - \boldsymbol{\mu}) \xrightarrow{d} N(\mathbf{0}, \boldsymbol{\Sigma})$$

---

## 9. MGF를 이용한 증명 개요

### 아이디어
MGF의 수렴 ⟺ 분포의 수렴 (동치)

### 증명 스케치
1변량 CLT를 이용:
$$\lambda^T \sqrt{N}(\bar{\mathbf{X}}_N - \boldsymbol{\mu}) \xrightarrow{d} N(0, \lambda^T \boldsymbol{\Sigma} \lambda)$$

for all $\lambda \in \mathbb{R}^k$

**Cramér-Wold 장치(device)** 적용:
- 모든 선형결합 $\lambda^T \mathbf{Y}$가 정규분포로 수렴하면
- $\mathbf{Y}$ 자체도 다변량 정규분포로 수렴

---

## 10. 핵심 공식 정리

| 개념 | 공식 |
|------|------|
| 선형변환 기댓값 | $E[B\mathbf{X} + \mathbf{b}] = B\boldsymbol{\mu} + \mathbf{b}$ |
| 선형변환 분산 | $\text{Var}(B\mathbf{X}) = B\boldsymbol{\Sigma}B^T$ |
| 다변량 CLT | $\sqrt{N}(\bar{\mathbf{X}}_N - \boldsymbol{\mu}) \xrightarrow{d} N(\mathbf{0}, \boldsymbol{\Sigma})$ |

---

## 11. 이 강의의 핵심 메시지

1. **양정치 행렬의 중요성**
   - 공분산 행렬은 항상 양정치 (또는 양반정치)
   - $\boldsymbol{\Sigma} = AA^T$ 분해 가능

2. **선형변환의 분산 공식**
   - $\text{Var}(B\mathbf{X}) = B\boldsymbol{\Sigma}B^T$

3. **다변량 CLT**
   - 1변량 CLT의 자연스러운 확장
   - 표본평균 벡터 → 다변량 정규분포

4. **Cramér-Wold 장치**
   - 선형결합의 수렴으로 다변량 수렴 증명

---

## 12. Q&A

### Q1. Cramér-Wold 장치란?

**정리:** 모든 $\lambda \in \mathbb{R}^k$에 대해
$$\lambda^T \mathbf{Y}_N \xrightarrow{d} \lambda^T \mathbf{Y}$$
이면
$$\mathbf{Y}_N \xrightarrow{d} \mathbf{Y}$$

**직관:** 모든 "방향"에서의 1차원 투영이 수렴하면, 전체 벡터도 수렴!

### Q2. 왜 $\sqrt{N}$을 곱하나?

**문제:** $\sqrt{N}$ 없이 그냥 $\bar{X}_N - \mu$를 보면?

$$\text{Var}(\bar{X}_N) = \frac{\sigma^2}{N} \xrightarrow{N \to \infty} 0$$

분산이 0으로 수렴 → 분포가 **점으로 수축** 😵

**해결: $\sqrt{N}$으로 스케일링!**

$$\text{Var}(\sqrt{N}(\bar{X}_N - \mu)) = N \cdot \frac{\sigma^2}{N} = \sigma^2$$

분산이 $\sigma^2$로 **일정** → 의미 있는 극한 분포!

**비교표:**

| | 분산 | N → ∞ |
|---|------|-------|
| $\bar{X}_N - \mu$ | $\frac{\sigma^2}{N}$ → 0 | 점으로 수축 😵 |
| $\sqrt{N}(\bar{X}_N - \mu)$ | $\sigma^2$ (일정) | $N(0, \sigma^2)$로 수렴 ✅ |

> **$\sqrt{N}$ = 분산 스케일링 보정! 의미 있는 극한 분포를 얻기 위한 필수 조치**
